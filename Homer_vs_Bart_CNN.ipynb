{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyMUZBLJzIjC47UBr28a/sx3",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/dede0702/Homer-vs-Bart-CNN/blob/main/Homer_vs_Bart_CNN.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "tuyOh1sTbrKg"
      },
      "outputs": [],
      "source": [
        "```python\n",
        "# Introdução:\n",
        "# Este código implementa um modelo de Classificação de Imagens usando uma Rede Neural Convolucional (CNN)\n",
        "# para classificar personagens de desenhos animados (Homer e Bart Simpson). O código utiliza o framework PyTorch\n",
        "# e uma arquitetura ResNet18 pré-treinada para um aprendizado mais eficiente. O dataset é carregado,\n",
        "# pré-processado, e usado para treinar o modelo. Após o treinamento, o modelo é avaliado e salvo,\n",
        "# e algumas predições são visualizadas.\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import ImageFolder\n",
        "from torch.utils.data import DataLoader\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "\n",
        "# Define o device (GPU se disponível, senão CPU)\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
        "\n",
        "# Parâmetros\n",
        "data_dir = \"dataset_personagens\" # Diretório do dataset\n",
        "num_epochs = 25  # Número de épocas de treinamento\n",
        "batch_size = 32 # Tamanho do batch\n",
        "learning_rate = 0.001 # Taxa de aprendizado\n",
        "\n",
        "# Transformações de dados: redimensiona, converte para tensor e normaliza as imagens\n",
        "data_transforms = {\n",
        "    'training_set': transforms.Compose([\n",
        "        transforms.Resize((224, 224)),  # Redimensiona as imagens para o tamanho exigido pela ResNet18\n",
        "        transforms.ToTensor(), # Converte as imagens para tensores PyTorch\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225]) # Normaliza as imagens usando média e desvio padrão do ImageNet\n",
        "    ]),\n",
        "    'test_set': transforms.Compose([\n",
        "        transforms.Resize((224, 224)),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ]),\n",
        "}\n",
        "\n",
        "# Carrega os datasets usando ImageFolder, que organiza as imagens por pasta (classe)\n",
        "image_datasets = {x: ImageFolder(os.path.join(data_dir, x), data_transforms[x])\n",
        "                  for x in ['training_set', 'test_set']}\n",
        "\n",
        "# Cria DataLoaders para carregar os dados em batches durante o treinamento\n",
        "dataloaders = {x: DataLoader(image_datasets[x], batch_size=batch_size, shuffle=True) # shuffle=True embaralha os dados de treino\n",
        "              for x in ['training_set', 'test_set']}\n",
        "\n",
        "# Obtém o tamanho de cada dataset\n",
        "dataset_sizes = {x: len(image_datasets[x]) for x in ['training_set', 'test_set']}\n",
        "# Obtém os nomes das classes\n",
        "class_names = image_datasets['training_set'].classes\n",
        "\n",
        "# Definição do modelo: usa uma ResNet18 pré-treinada\n",
        "model = torch.models.resnet18(pretrained=True) # Carrega o modelo ResNet18 pré-treinado no ImageNet\n",
        "num_ftrs = model.fc.in_features # Obtém o número de features da penúltima camada\n",
        "model.fc = nn.Linear(num_ftrs, len(class_names))  # Substitui a camada totalmente conectada final para corresponder ao número de classes do nosso dataset\n",
        "model = model.to(device) # Move o modelo para o device (GPU ou CPU)\n",
        "\n",
        "\n",
        "# Função de Treinamento\n",
        "def train_model(model, criterion, optimizer, num_epochs=25):\n",
        "\n",
        "    for epoch in range(num_epochs): # Loop pelas épocas\n",
        "        print(f'Epoch {epoch + 1}/{num_epochs}')\n",
        "        print('-' * 10)\n",
        "\n",
        "        for phase in ['training_set', 'test_set']: # Loop pelas fases (treino e teste)\n",
        "            if phase == 'training_set':\n",
        "                model.train()  # Define o modelo para o modo de treinamento\n",
        "            else:\n",
        "                model.eval()   # Define o modelo para o modo de avaliação\n",
        "\n",
        "            running_loss = 0.0 # Variável para acumular o loss da época\n",
        "            running_corrects = 0 # Variável para acumular o número de predições corretas\n",
        "\n",
        "            for inputs, labels in dataloaders[phase]: # Loop pelos batches de dados\n",
        "                inputs = inputs.to(device) # Move os inputs para o device\n",
        "                labels = labels.to(device) # Move os labels para o device\n",
        "\n",
        "                optimizer.zero_grad() # Zera os gradientes do otimizador\n",
        "\n",
        "                with torch.set_grad_enabled(phase == 'training_set'):  # Calcula os gradientes apenas durante o treino\n",
        "                    outputs = model(inputs) # Passa os inputs pelo modelo\n",
        "                    _, preds = torch.max(outputs, 1) # Obtém as predições\n",
        "                    loss = criterion(outputs, labels) # Calcula o loss\n",
        "\n",
        "                    if phase == 'training_set':\n",
        "                        loss.backward() # Calcula os gradientes\n",
        "                        optimizer.step() # Atualiza os pesos do modelo\n",
        "\n",
        "\n",
        "                running_loss += loss.item() * inputs.size(0) # Acumula o loss\n",
        "                running_corrects += torch.sum(preds == labels.data) # Acumula o número de predições corretas\n",
        "\n",
        "            epoch_loss = running_loss / dataset_sizes[phase] # Calcula o loss médio da época\n",
        "            epoch_acc = running_corrects.double() / dataset_sizes[phase] # Calcula a acurácia da época\n",
        "\n",
        "            print(f'{phase} Loss: {epoch_loss:.4f} Acc: {epoch_acc:.4f}')\n",
        "\n",
        "    return model\n",
        "\n",
        "# Define a função de perda (CrossEntropyLoss para classificação multiclasse)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "# Define o otimizador (Adam)\n",
        "optimizer = optim.Adam(model.parameters(), lr=learning_rate)\n",
        "# Treina o modelo\n",
        "model = train_model(model, criterion, optimizer, num_epochs=num_epochs)\n",
        "\n",
        "\n",
        "# Salva o modelo treinado\n",
        "torch.save(model.state_dict(), 'modelo_treinado.pth')\n",
        "\n",
        "# Função para visualizar algumas predições do modelo\n",
        "def visualize_model(model, num_images=6):\n",
        "    was_training = model.training\n",
        "    model.eval()\n",
        "    images_so_far = 0\n",
        "    fig = plt.figure()\n",
        "\n",
        "    with torch.no_grad():\n",
        "        for i, (inputs, labels) in enumerate(dataloaders['test_set']):\n",
        "            inputs = inputs.to(device)\n",
        "            labels = labels.to(device)\n",
        "\n",
        "            outputs = model(inputs)\n",
        "            _, preds = torch.max(outputs, 1)\n",
        "\n",
        "            for j in range(inputs.size()[0]):\n",
        "                images_so_far += 1\n",
        "                ax = plt.subplot(num_images // 2, 2, images_so_far)\n",
        "                ax.axis('off')\n",
        "                ax.set_title(f'predicted: {class_names[preds[j]]}')\n",
        "                imshow(inputs.cpu().data[j])\n",
        "\n",
        "                if images_so_far == num_images:\n",
        "                    model.train(mode=was_training)\n",
        "                    return\n",
        "        model.train(mode=was_training)\n",
        "\n",
        "\n",
        "\n",
        "def imshow(inp, title=None):\n",
        "    \"\"\"Imshow para Tensores.\"\"\"\n",
        "    inp = inp.numpy().transpose((1, 2, 0))\n",
        "    mean = np.array([0.485, 0.456, 0.406])\n",
        "    std = np.array([0.229, 0.224, 0.225])\n",
        "    inp = std * inp + mean\n",
        "    inp = np.clip(inp, 0, 1)\n",
        "    plt.imshow(inp)\n",
        "    if title is not None:\n",
        "        plt.title(title)\n",
        "    plt.pause(0.001)  # pause a bit so that plots are updated\n",
        "\n",
        "\n",
        "\n",
        "visualize_model(model) # Visualiza as predições\n",
        "plt.ioff()\n",
        "plt.show()\n",
        "\n",
        "\n",
        "# Conclusão:\n",
        "# O código implementa um modelo de classificação de imagens utilizando uma CNN ResNet18 pré-treinada\n",
        "# para classificar personagens de desenhos animados. A utilização de um modelo pré-treinado permite um\n",
        "# treinamento mais rápido e eficiente. O código inclui etapas de pré-processamento de dados, treinamento,\n",
        "# avaliação, salvamento do modelo e visualização de predições, fornecendo uma solução completa para\n",
        "# o problema de classificação de imagens.\n",
        "```\n",
        "\n",
        "\n",
        "Algumas pequenas melhorias foram adicionadas aos comentários para maior clareza.  Este código agora está bem documentado e pronto para ser executado!"
      ]
    }
  ]
}